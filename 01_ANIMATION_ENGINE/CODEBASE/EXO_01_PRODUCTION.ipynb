{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ TRANSMUTATION PRODUCTION ‚Äî Batch Processing\n",
        "\n",
        "```\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë                 FR√âGATE 01_TRANSMUTATION ‚Äî PRODUCTION MODE                   ‚ïë\n",
        "‚ïë              Batch Processing ‚Ä¢ Multi-Actor ‚Ä¢ Full Pipeline                  ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "```\n",
        "\n",
        "**Mission**: Traiter plusieurs acteurs en batch via le pipeline TRANSMUTATION complet.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Setup Production Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configuration\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/DRIVE_EXODUS_V2\"\n",
        "UNIT_ROOT = f\"{DRIVE_ROOT}/01_ANIMATION_ENGINE\"\n",
        "CODEBASE = f\"{UNIT_ROOT}/CODEBASE\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, CODEBASE)\n",
        "\n",
        "print(\"‚ïî\" + \"‚ïê\" * 50 + \"‚ïó\")\n",
        "print(\"‚ïë   TRANSMUTATION PRODUCTION ‚Äî EXODUS SYSTEM        ‚ïë\")\n",
        "print(\"‚ïö\" + \"‚ïê\" * 50 + \"‚ïù\")\n",
        "print(f\"\\n‚úì Environment configured\")\n",
        "print(f\"‚úì Drive Root: {DRIVE_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision opencv-python-headless scipy omegaconf Pillow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup Blender 4.0 (si pas d√©j√† sur le Drive)\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "BLENDER_PATH = f\"{DRIVE_ROOT}/EXODUS_AI_MODELS/blender-4.0.0-linux-x64/blender\"\n",
        "\n",
        "if not Path(BLENDER_PATH).exists():\n",
        "    print(\"‚ö† Blender 4.0 non trouv√© sur le Drive\")\n",
        "    print(\"T√©l√©chargement automatique...\")\n",
        "    \n",
        "    !mkdir -p {DRIVE_ROOT}/EXODUS_AI_MODELS\n",
        "    !wget -q https://download.blender.org/release/Blender4.0/blender-4.0.0-linux-x64.tar.xz -O /tmp/blender.tar.xz\n",
        "    !tar -xf /tmp/blender.tar.xz -C {DRIVE_ROOT}/EXODUS_AI_MODELS/\n",
        "    !rm /tmp/blender.tar.xz\n",
        "    \n",
        "    print(\"‚úì Blender 4.0 install√©\")\n",
        "else:\n",
        "    print(f\"‚úì Blender 4.0 trouv√©: {BLENDER_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Configuration Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration des jobs batch\n",
        "# Chaque job: (body_fbx, video, actor_blend, output_name, sync_offset)\n",
        "\n",
        "BATCH_JOBS = [\n",
        "    {\n",
        "        \"name\": \"ACTOR_01\",\n",
        "        \"body_fbx\": \"dance_motion_01.fbx\",\n",
        "        \"video\": \"face_capture_01.mp4\",\n",
        "        \"actor_blend\": \"roblox_avatar_01.blend\",\n",
        "        \"sync_offset\": 0,\n",
        "        \"smooth_window\": 5\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"ACTOR_02\",\n",
        "        \"body_fbx\": \"dance_motion_01.fbx\",  # M√™me body motion\n",
        "        \"video\": \"face_capture_02.mp4\",     # Visage diff√©rent\n",
        "        \"actor_blend\": \"roblox_avatar_02.blend\",\n",
        "        \"sync_offset\": 15,\n",
        "        \"smooth_window\": 7\n",
        "    },\n",
        "    # Ajouter d'autres jobs ici...\n",
        "]\n",
        "\n",
        "print(f\"Jobs configur√©s: {len(BATCH_JOBS)}\")\n",
        "for i, job in enumerate(BATCH_JOBS):\n",
        "    print(f\"  {i+1}. {job['name']}: {job['body_fbx']} + {job['video']} ‚Üí {job['actor_blend']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Validation Pre-Flight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# V√©rifier que tous les fichiers existent avant de lancer\n",
        "from pathlib import Path\n",
        "\n",
        "def validate_job(job):\n",
        "    \"\"\"Valide qu'un job a tous ses fichiers.\"\"\"\n",
        "    errors = []\n",
        "    \n",
        "    body_path = Path(f\"{UNIT_ROOT}/IN_INPUTS/body_motions/{job['body_fbx']}\")\n",
        "    if not body_path.exists():\n",
        "        errors.append(f\"Body FBX manquant: {job['body_fbx']}\")\n",
        "    \n",
        "    video_path = Path(f\"{UNIT_ROOT}/IN_INPUTS/source_videos/{job['video']}\")\n",
        "    if not video_path.exists():\n",
        "        errors.append(f\"Video manquante: {job['video']}\")\n",
        "    \n",
        "    actor_path = Path(f\"{UNIT_ROOT}/IN_INPUTS/actor_models/{job['actor_blend']}\")\n",
        "    if not actor_path.exists():\n",
        "        errors.append(f\"Actor manquant: {job['actor_blend']}\")\n",
        "    \n",
        "    return errors\n",
        "\n",
        "print(\"=== Validation Pre-Flight ===\")\n",
        "all_valid = True\n",
        "\n",
        "for job in BATCH_JOBS:\n",
        "    errors = validate_job(job)\n",
        "    if errors:\n",
        "        all_valid = False\n",
        "        print(f\"\\n‚úó {job['name']}:\")\n",
        "        for err in errors:\n",
        "            print(f\"   - {err}\")\n",
        "    else:\n",
        "        print(f\"‚úì {job['name']}: tous les fichiers pr√©sents\")\n",
        "\n",
        "if all_valid:\n",
        "    print(\"\\n‚úì VALIDATION OK ‚Äî Pr√™t pour production\")\n",
        "else:\n",
        "    print(\"\\n‚úó VALIDATION √âCHOU√âE ‚Äî V√©rifiez les fichiers manquants\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè≠ Ex√©cution Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def run_transmutation(job):\n",
        "    \"\"\"Ex√©cute le pipeline TRANSMUTATION pour un job.\"\"\"\n",
        "    start_time = time.time()\n",
        "    \n",
        "    cmd = [\n",
        "        \"python\", f\"{CODEBASE}/EXO_01_TRANSMUTATION.py\",\n",
        "        \"--drive-root\", DRIVE_ROOT,\n",
        "        \"--body-fbx\", job[\"body_fbx\"],\n",
        "        \"--video\", job[\"video\"],\n",
        "        \"--actor-blend\", job[\"actor_blend\"],\n",
        "        \"--output-name\", job[\"name\"],\n",
        "        \"--sync-offset\", str(job.get(\"sync_offset\", 0)),\n",
        "        \"--smooth-window\", str(job.get(\"smooth_window\", 5)),\n",
        "        \"-v\"\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSING: {job['name']}\")\n",
        "    print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(f\"\\n‚úì {job['name']} COMPL√âT√â en {elapsed:.1f}s\")\n",
        "        return True, elapsed\n",
        "    else:\n",
        "        print(f\"\\n‚úó {job['name']} √âCHOU√â\")\n",
        "        print(f\"STDERR: {result.stderr}\")\n",
        "        return False, elapsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ex√©cuter tous les jobs\n",
        "results = []\n",
        "total_start = time.time()\n",
        "\n",
        "print(\"‚ïî\" + \"‚ïê\" * 50 + \"‚ïó\")\n",
        "print(\"‚ïë       TRANSMUTATION BATCH ‚Äî D√âMARRAGE             ‚ïë\")\n",
        "print(\"‚ïö\" + \"‚ïê\" * 50 + \"‚ïù\")\n",
        "print(f\"\\nJobs √† traiter: {len(BATCH_JOBS)}\")\n",
        "\n",
        "for i, job in enumerate(BATCH_JOBS):\n",
        "    print(f\"\\n[{i+1}/{len(BATCH_JOBS)}] Processing {job['name']}...\")\n",
        "    \n",
        "    # Validation\n",
        "    errors = validate_job(job)\n",
        "    if errors:\n",
        "        print(f\"  ‚ö† Skipped (fichiers manquants)\")\n",
        "        results.append((job['name'], False, 0, \"Fichiers manquants\"))\n",
        "        continue\n",
        "    \n",
        "    # Ex√©cution\n",
        "    success, elapsed = run_transmutation(job)\n",
        "    results.append((job['name'], success, elapsed, \"\" if success else \"Pipeline error\"))\n",
        "\n",
        "total_elapsed = time.time() - total_start\n",
        "\n",
        "# R√©sum√©\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"BATCH TERMIN√â ‚Äî R√âSUM√â\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "success_count = sum(1 for r in results if r[1])\n",
        "print(f\"\\nSucc√®s: {success_count}/{len(results)}\")\n",
        "print(f\"Temps total: {total_elapsed:.1f}s\")\n",
        "\n",
        "print(\"\\nD√©tails:\")\n",
        "for name, success, elapsed, error in results:\n",
        "    status = \"‚úì\" if success else \"‚úó\"\n",
        "    print(f\"  {status} {name}: {elapsed:.1f}s {error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ V√©rification Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lister les fichiers g√©n√©r√©s\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(f\"{UNIT_ROOT}/OUT_BAKED\")\n",
        "\n",
        "print(\"=== Fichiers G√©n√©r√©s ===\")\n",
        "print(f\"Dossier: {output_dir}\\n\")\n",
        "\n",
        "if output_dir.exists():\n",
        "    files = sorted(output_dir.glob(\"*\"))\n",
        "    \n",
        "    abc_files = [f for f in files if f.suffix == '.abc']\n",
        "    json_files = [f for f in files if f.suffix == '.json']\n",
        "    \n",
        "    print(f\"Alembic (.abc): {len(abc_files)}\")\n",
        "    for f in abc_files:\n",
        "        size_mb = f.stat().st_size / (1024 * 1024)\n",
        "        print(f\"  üì¶ {f.name} ({size_mb:.2f} MB)\")\n",
        "    \n",
        "    print(f\"\\nFace Data (.json): {len(json_files)}\")\n",
        "    for f in json_files:\n",
        "        size_kb = f.stat().st_size / 1024\n",
        "        print(f\"  üìÑ {f.name} ({size_kb:.1f} KB)\")\n",
        "else:\n",
        "    print(\"Dossier output non trouv√©\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Rapport de Production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# G√©n√©rer rapport de production\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "report = {\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"total_jobs\": len(BATCH_JOBS),\n",
        "    \"successful\": success_count,\n",
        "    \"failed\": len(results) - success_count,\n",
        "    \"total_time_seconds\": total_elapsed,\n",
        "    \"jobs\": [\n",
        "        {\n",
        "            \"name\": name,\n",
        "            \"success\": success,\n",
        "            \"time_seconds\": elapsed,\n",
        "            \"error\": error\n",
        "        }\n",
        "        for name, success, elapsed, error in results\n",
        "    ]\n",
        "}\n",
        "\n",
        "report_path = f\"{UNIT_ROOT}/OUT_BAKED/production_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(report_path, 'w') as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print(f\"‚úì Rapport sauvegard√©: {report_path}\")\n",
        "print(f\"\\n{json.dumps(report, indent=2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ‚úÖ Production Complete\n",
        "\n",
        "Les fichiers `.abc` sont pr√™ts pour import dans:\n",
        "- Blender (pour rendu)\n",
        "- Unity (via Alembic Importer)\n",
        "- Roblox (conversion n√©cessaire)\n",
        "\n",
        "**Next Step**: Utiliser U02_LOGISTICS pour packager les assets."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
