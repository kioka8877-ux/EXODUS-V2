{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîß TRANSMUTATION CONTROL ‚Äî Debug & Testing\n",
        "\n",
        "```\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë                 FR√âGATE 01_TRANSMUTATION ‚Äî CONTROL PANEL                     ‚ïë\n",
        "‚ïë                    Debug ‚Ä¢ Test EMOCA ‚Ä¢ Inspect ‚Ä¢ Preview                    ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "```\n",
        "\n",
        "**Objectif**: Tester individuellement chaque composant du pipeline TRANSMUTATION.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Setup & Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configuration\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/DRIVE_EXODUS_V2\"\n",
        "UNIT_ROOT = f\"{DRIVE_ROOT}/01_ANIMATION_ENGINE\"\n",
        "CODEBASE = f\"{UNIT_ROOT}/CODEBASE\"\n",
        "\n",
        "# Add codebase to path\n",
        "import sys\n",
        "sys.path.insert(0, CODEBASE)\n",
        "\n",
        "print(f\"‚úì Drive mont√©\")\n",
        "print(f\"‚úì Unit Root: {UNIT_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision opencv-python-headless scipy omegaconf Pillow tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Test 1: V√©rification des Chemins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "paths_to_check = [\n",
        "    (\"Unit Root\", UNIT_ROOT),\n",
        "    (\"Codebase\", CODEBASE),\n",
        "    (\"IN_INPUTS\", f\"{UNIT_ROOT}/IN_INPUTS\"),\n",
        "    (\"OUT_BAKED\", f\"{UNIT_ROOT}/OUT_BAKED\"),\n",
        "    (\"Body Motions\", f\"{UNIT_ROOT}/IN_INPUTS/body_motions\"),\n",
        "    (\"Source Videos\", f\"{UNIT_ROOT}/IN_INPUTS/source_videos\"),\n",
        "    (\"Actor Models\", f\"{UNIT_ROOT}/IN_INPUTS/actor_models\"),\n",
        "]\n",
        "\n",
        "print(\"=== V√©rification Chemins ===\")\n",
        "for name, path in paths_to_check:\n",
        "    exists = Path(path).exists()\n",
        "    status = \"‚úì\" if exists else \"‚úó\"\n",
        "    print(f\"{status} {name}: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lister les fichiers disponibles\n",
        "import os\n",
        "\n",
        "print(\"\\n=== Fichiers Inputs ===\")\n",
        "\n",
        "for folder in [\"body_motions\", \"source_videos\", \"actor_models\"]:\n",
        "    folder_path = f\"{UNIT_ROOT}/IN_INPUTS/{folder}\"\n",
        "    print(f\"\\nüìÅ {folder}:\")\n",
        "    if Path(folder_path).exists():\n",
        "        files = [f for f in os.listdir(folder_path) if not f.startswith('.')]\n",
        "        if files:\n",
        "            for f in files:\n",
        "                print(f\"   - {f}\")\n",
        "        else:\n",
        "            print(\"   (vide)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≠ Test 2: EMOCA Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Facial Extractor\n",
        "from facial_extractor import EMOCAExtractor, ARKIT_52_BLENDSHAPES\n",
        "\n",
        "print(f\"ARKit Blendshapes support√©s: {len(ARKIT_52_BLENDSHAPES)}\")\n",
        "print(\"\\nListe compl√®te:\")\n",
        "for i, name in enumerate(ARKIT_52_BLENDSHAPES):\n",
        "    print(f\"  {i+1:2d}. {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test extraction sur une vid√©o (si disponible)\n",
        "TEST_VIDEO = f\"{UNIT_ROOT}/IN_INPUTS/source_videos/test.mp4\"  # Modifier selon fichier disponible\n",
        "EMOCA_PATH = f\"{DRIVE_ROOT}/EXODUS_AI_MODELS/emoca\"\n",
        "\n",
        "if Path(TEST_VIDEO).exists():\n",
        "    print(f\"Test vid√©o trouv√©e: {TEST_VIDEO}\")\n",
        "    \n",
        "    extractor = EMOCAExtractor(EMOCA_PATH)\n",
        "    \n",
        "    # Extraire seulement 30 frames pour le test\n",
        "    face_data = extractor.extract_arkit_from_video(TEST_VIDEO, end_frame=30)\n",
        "    \n",
        "    print(f\"\\nR√©sultat:\")\n",
        "    print(f\"  FPS: {face_data['fps']}\")\n",
        "    print(f\"  Frames: {len(face_data['frames'])}\")\n",
        "    \n",
        "    if face_data['frames']:\n",
        "        sample = face_data['frames'][0]\n",
        "        print(f\"\\n√âchantillon Frame 0:\")\n",
        "        for key, val in list(sample['blendshapes'].items())[:10]:\n",
        "            print(f\"    {key}: {val:.4f}\")\n",
        "else:\n",
        "    print(f\"Aucune vid√©o test trouv√©e √†: {TEST_VIDEO}\")\n",
        "    print(\"Placez une vid√©o .mp4 dans IN_INPUTS/source_videos/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Test 3: Synchronisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sync_engine import SyncEngine\n",
        "\n",
        "sync = SyncEngine(verbose=True)\n",
        "\n",
        "# Test m√©thode marqueur\n",
        "print(\"=== Test Sync Engine ===\")\n",
        "\n",
        "# Exemple: dans la vid√©o, le clap est √† la frame 150\n",
        "#          dans le FBX, le mouvement commence √† la frame 100\n",
        "offset = sync.calculate_offset(\n",
        "    method=\"marker\",\n",
        "    marker_video=150,\n",
        "    marker_fbx=100\n",
        ")\n",
        "\n",
        "print(f\"\\nOffset calcul√©: {offset} frames\")\n",
        "print(\"‚Üí Signifie: la vid√©o est en avance de 50 frames sur le FBX\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation sync\n",
        "is_valid, msg = sync.validate_sync(\n",
        "    body_length=1000,  # FBX a 1000 frames\n",
        "    face_length=900,   # Vid√©o a 900 frames\n",
        "    offset=50\n",
        ")\n",
        "\n",
        "print(f\"Validation: {msg}\")\n",
        "\n",
        "start, end = sync.get_frame_range(1000, 900, 50)\n",
        "print(f\"Plage effective: frames {start} - {end}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Test 4: Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from smoothing import savgol_smooth, adaptive_smooth, compute_smoothing_metrics\n",
        "\n",
        "# G√©n√©rer signal test avec bruit\n",
        "np.random.seed(42)\n",
        "n_frames = 100\n",
        "t = np.linspace(0, 2 * np.pi, n_frames)\n",
        "\n",
        "# Signal: smile qui monte puis descend\n",
        "clean_signal = np.sin(t) * 0.4 + 0.5\n",
        "noisy_signal = clean_signal + np.random.normal(0, 0.08, n_frames)\n",
        "noisy_signal = np.clip(noisy_signal, 0, 1)\n",
        "\n",
        "# Appliquer lissage\n",
        "smoothed = savgol_smooth(noisy_signal, window=7)\n",
        "\n",
        "print(\"=== Test Smoothing ===\")\n",
        "print(f\"Signal original: mean={np.mean(noisy_signal):.3f}, std={np.std(noisy_signal):.3f}\")\n",
        "print(f\"Signal liss√©: mean={np.mean(smoothed):.3f}, std={np.std(smoothed):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(noisy_signal, alpha=0.5, label='Brut (avec bruit)')\n",
        "plt.plot(smoothed, linewidth=2, label='Liss√© (Savitzky-Golay)')\n",
        "plt.plot(clean_signal, '--', alpha=0.7, label='Signal original')\n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('Blendshape Value')\n",
        "plt.title('Comparaison Smoothing')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Test 5: Dry Run Pipeline Complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test dry-run du script principal\n",
        "!python {CODEBASE}/EXO_01_TRANSMUTATION.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple de dry-run (validation chemins sans ex√©cution)\n",
        "# D√©commenter et adapter les noms de fichiers\n",
        "\n",
        "# !python {CODEBASE}/EXO_01_TRANSMUTATION.py \\\n",
        "#     --drive-root {DRIVE_ROOT} \\\n",
        "#     --body-fbx motion.fbx \\\n",
        "#     --video source.mp4 \\\n",
        "#     --actor-blend avatar.blend \\\n",
        "#     --dry-run -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Inspection Face Data JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def inspect_face_json(json_path):\n",
        "    \"\"\"Inspecte un fichier JSON de donn√©es faciales.\"\"\"\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    print(f\"=== Inspection: {json_path} ===\")\n",
        "    print(f\"FPS: {data.get('fps', 'N/A')}\")\n",
        "    print(f\"Total Frames: {data.get('total_frames', len(data.get('frames', [])))}\")\n",
        "    print(f\"Frames extraites: {len(data.get('frames', []))}\")\n",
        "    \n",
        "    if data.get('frames'):\n",
        "        # Stats par blendshape\n",
        "        import numpy as np\n",
        "        \n",
        "        blendshape_names = list(data['frames'][0]['blendshapes'].keys())\n",
        "        \n",
        "        print(f\"\\nBlendshapes: {len(blendshape_names)}\")\n",
        "        print(\"\\nTop 10 blendshapes actifs (par max):\")\n",
        "        \n",
        "        max_values = {}\n",
        "        for name in blendshape_names:\n",
        "            values = [f['blendshapes'].get(name, 0) for f in data['frames']]\n",
        "            max_values[name] = max(values)\n",
        "        \n",
        "        sorted_bs = sorted(max_values.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "        for name, val in sorted_bs:\n",
        "            print(f\"  {name}: {val:.3f}\")\n",
        "\n",
        "# Exemple d'utilisation (d√©commenter si fichier existe)\n",
        "# inspect_face_json(f\"{UNIT_ROOT}/OUT_BAKED/test_face.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ‚úÖ Checklist Debug\n",
        "\n",
        "- [ ] Chemins v√©rifi√©s\n",
        "- [ ] EMOCA fonctionne\n",
        "- [ ] Sync calcul√© correctement\n",
        "- [ ] Smoothing r√©duit le bruit\n",
        "- [ ] Dry-run passe"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
